{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62586e0cd396bf4e",
   "metadata": {},
   "source": [
    "# Generate Documentation using Amazon Q for Business and evaluate it against existing documentation.\n",
    "\n",
    "In this notebook we will use Amazon Q for Business to generate a documentation for repo files, ingest them to Amazon Q, get documentation repo, iterate through its files, ask questions to Q about documented functionality and then compare AI-geenrated vs human generated doc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a5b6faf5d06098e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.34.67)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.34.72-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting botocore<1.35.0,>=1.34.72 (from boto3)\n",
      "  Downloading botocore-1.34.72-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore<1.35.0,>=1.34.72->boto3) (2.8.2)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore<1.35.0,>=1.34.72->boto3) (2.0.7)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.72->boto3) (1.16.0)\n",
      "Downloading boto3-1.34.72-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading botocore-1.34.72-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: botocore, boto3\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.34.67\n",
      "    Uninstalling botocore-1.34.67:\n",
      "      Successfully uninstalled botocore-1.34.67\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.34.67\n",
      "    Uninstalling boto3-1.34.67:\n",
      "      Successfully uninstalled boto3-1.34.67\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.32.67 requires botocore==1.34.67, but you have botocore 1.34.72 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed boto3-1.34.72 botocore-1.34.72\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting GitPython\n",
      "  Using cached GitPython-3.1.42-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting shutils\n",
      "  Downloading shutils-0.1.0.tar.gz (2.3 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting python-dotenv\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from GitPython)\n",
      "  Using cached gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting configparser (from shutils)\n",
      "  Downloading configparser-6.0.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pymysql (from shutils)\n",
      "  Downloading PyMySQL-1.1.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython)\n",
      "  Using cached smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Using cached GitPython-3.1.42-py3-none-any.whl (195 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Using cached gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "Downloading configparser-6.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading PyMySQL-1.1.0-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: shutils\n",
      "  Building wheel for shutils (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for shutils: filename=shutils-0.1.0-py3-none-any.whl size=3274 sha256=a5fbb52e3cf93e8da03ffa69aca826a11848dd5013b37488d7e8c506508c4a45\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/62/63/04/81e549bdb44792d8b62938cffc3bd00a34addabe1da3693db8\n",
      "Successfully built shutils\n",
      "Installing collected packages: smmap, python-dotenv, pymysql, configparser, shutils, gitdb, GitPython\n",
      "Successfully installed GitPython-3.1.42 configparser-6.0.1 gitdb-4.0.11 pymysql-1.1.0 python-dotenv-1.0.1 shutils-0.1.0 smmap-5.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install boto3 --upgrade \n",
    "%pip install GitPython shutils python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17218288f17629a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T10:49:05.207504Z",
     "start_time": "2024-03-05T10:49:05.126356Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import time\n",
    "import json\n",
    "import datetime\n",
    "import requests\n",
    "import re\n",
    "import logging\n",
    "import shutil\n",
    "import uuid\n",
    "import git\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "feb52bcb-e77f-400e-b328-261cf6ad2a91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing .env\n"
     ]
    }
   ],
   "source": [
    "%%writefile .env\n",
    "TOKEN_NAME=amazon-q-use-case-1-private\n",
    "DOC_REPO_URL=https://github.com/bayer-int/DSE-DevDocs.git\n",
    "CODE_REPO_URL=https://github.com/bayer-int/dse-apis.git\n",
    "DOC_REPO_SUBDIR=docs/platform_developer/APIs\n",
    "FILE_DOC_SUFFIX=API\n",
    "USERNAME=sviola-bayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da359ee229afbd5d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c45c6d99-ecd1-44f6-86f4-2a31d0d20366",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GitHub authentication token\n",
    "token_name = os.environ['TOKEN_NAME']\n",
    "\n",
    "# Repository owner, name etc\n",
    "# this will be env vars in Lambda\n",
    "# owner = os.environ['OWNER']\n",
    "code_repo = os.environ['CODE_REPO_URL']\n",
    "doc_repo = os.environ['DOC_REPO_URL']\n",
    "doc_repo_subdir = os.environ['DOC_REPO_SUBDIR']\n",
    "suffix = os.environ['FILE_DOC_SUFFIX']\n",
    "username = os.environ['USERNAME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9c59a6b-936d-42d9-aadf-3fdb1ea5513b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s %(levelname)s %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "    handlers=[\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe1de909-e349-4a00-8279-bc4a136226eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "secretsmanager = boto3.client('secretsmanager')\n",
    "amazon_q = boto3.client('qbusiness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f200fab390578a8a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "amazon_q_user_id = \"splwis@amazon.pl\"\n",
    "amazon_q_app_id = \"aac5cf2c-5ecc-4bea-bf74-25caf9636ace\"\n",
    "index_id = \"0476a6b0-af9c-418f-9a7c-ffe6b6299379\"\n",
    "role_arn = \"arn:aws:iam::643306558745:role/QBusiness-Application-Code-Analysis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dace242a-341b-48c2-a0ec-ffa3d2b2d278",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename = \".ipnybcheckpoint\"\n",
    "if filename.endswith('.md') and not filename.startswith('.'):\n",
    "    print(\"yes\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7a9eb262-4349-4131-ac91-5cbeb9efdc38",
   "metadata": {},
   "source": [
    "## Generating and Ingesting Documentation\n",
    "If we only ingest the code, we will be retrieving random code chunks that may not be relevant to the questions we want to ask. To avoid this, we will generate concise documentation for the repository and ingest it into the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a9cbb04-24cd-4532-b89b-f58c100eb62f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def include_code_file_type(filename):\n",
    "    if not filename.endswith(('.png', '.jpg', '.jpeg', '.gif', '.zip', '.md')) and not filename.startswith('.'):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def include_doc_file_type(filename):\n",
    "    if filename.endswith('.md') and not filename.startswith('.'):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def check_if_missing_response(answer):\n",
    "    if answer == \"Sorry, I could not find relevant information to complete your request.\":\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86b00af1-9b37-464b-9a9e-8a2d924fdba7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clone_repo(repo, token_name, local_path):\n",
    "    token = get_access_token(token_name)\n",
    "    _, repo_url = repo.split(\"https://\")\n",
    "    token_url = f\"https://{username}:{token}@{repo_url}\"\n",
    "    git.Repo.clone_from(token_url, local_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c041108d96c4e814",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ask_question_to_gen_code_doc(prompt, filename):\n",
    "    data = open(filename, 'rb')\n",
    "    answer = amazon_q.chat_sync(\n",
    "        applicationId=amazon_q_app_id,\n",
    "        userId=amazon_q_user_id,\n",
    "        userMessage=prompt,\n",
    "        attachments=[\n",
    "            {\n",
    "                'data': data.read(),\n",
    "                'name': filename\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "    return answer['systemMessage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88468acc-48ee-4bf8-b303-590f1255ccf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ask_question_to_gen_doc_summary(prompt):\n",
    "    answer = amazon_q.chat_sync(\n",
    "        applicationId=amazon_q_app_id,\n",
    "        userId=amazon_q_user_id,\n",
    "        userMessage=prompt,\n",
    "    )\n",
    "    return answer['systemMessage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f849ae0-611c-4162-965e-03a43cbbd4ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ask_question_to_compare_docs(prompt, human_gen_doc, ai_gen_doc):\n",
    "    answer = amazon_q.chat_sync(\n",
    "        applicationId=amazon_q_app_id,\n",
    "        userId=amazon_q_user_id,\n",
    "        userMessage=prompt,\n",
    "        attachments=[\n",
    "            {\n",
    "                'data': human_gen_doc,\n",
    "                'name': \"Human-Generated-Summary\"\n",
    "            },\n",
    "            {\n",
    "                'data': ai_gen_doc,\n",
    "                'name': \"AI-Generated-Summary\"\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "    return answer['systemMessage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b02c6f00-dd33-4bea-a2b9-0137d94a015d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def upload_prompt_answer_and_file_name(filename, prompt, answer, repo_url):\n",
    "    cleaned_file_name = os.path.join(repo_url[:-4], '/'.join(filename.split('/')[2:]))\n",
    "    amazon_q.batch_put_document(\n",
    "        applicationId=amazon_q_app_id,\n",
    "        indexId=index_id,\n",
    "        roleArn=role_arn,\n",
    "        documents=[\n",
    "            {\n",
    "                'id': str(uuid.uuid5(uuid.NAMESPACE_URL, f\"{cleaned_file_name}\")),\n",
    "                'contentType': 'PLAIN_TEXT',\n",
    "                'title': cleaned_file_name,\n",
    "                'content': {\n",
    "                    'blob': f\"{cleaned_file_name} | {prompt} | {answer}\".encode('utf-8')\n",
    "                },\n",
    "                'attributes': [\n",
    "                    {\n",
    "                        'name': 'url',\n",
    "                        'value': {\n",
    "                            'stringValue': cleaned_file_name\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            },\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4f8647e-fe39-4398-8d3c-65dfa87aba90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_access_token(secret_name):\n",
    "    response = secretsmanager.get_secret_value(SecretId=secret_name)\n",
    "    return response['SecretString']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72154af89ac2ba74",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_answers(answer, filepath, folder):\n",
    "    filepath = f\"{filepath}.out\"\n",
    "    with open(f\"{folder}/{filepath}\", \"w\") as f:\n",
    "        f.write(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f0efddf-6f44-4cc2-82d6-7c7c387b0c82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_doc_gen_prompts = [\n",
    "    \"Come up with a list of questions and answers about the attached file. Keep answers dense with information. A good question for a database related file would be 'What is the database technology and architecture?' or for a file that executes SQL commands 'What are the SQL commands and what do they do?' or for a file that contains a list of API endpoints 'What are the API endpoints and what do they do?'\",\n",
    "\n",
    "    \"Generate comprehensive documentation about the attached file. Make sure you include what dependencies and other files are being referenced as well as function names, class names, and what they do.\",\n",
    "\n",
    "    \"Identify anti-patterns in the attached file. Make sure to include examples of how to fix them. Try Q&A like 'What are some anti-patterns in the file?' or 'What could be causing high latency?'\",\n",
    "\n",
    "    \"Suggest improvements to the attached file. Try Q&A like 'What are some ways to improve the file?' or 'Where can the file be optimized?'\",\n",
    "\n",
    "    \"Please provide description of the attached file. Summarize the intent, resources and capabilities in separate sections.\",\n",
    "\n",
    "    \"Please describe each API method. Then list its inputs and outputs in a table. Include sample invocation.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da4c85d6-dfcd-49c4-86fb-0f5ea4f5a940",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_doc_summary_gen_prompt = \"Please provide me description <functionality> API in <repo_name>. Please include intent within a tag <intent></intent>, resources within a tag <resources></resources>, capabilities within a tag <capabilities></capabilities> in the subsequent paragraphs. In capabilities section you should explain all API methods, what is their purpose, inputs and outputs. Please include as much details as you can. This is important.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c009cb1-c623-476d-99a1-bd1d89b81b32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_doc_eval_prompt = \"<instruction>Evaluate the AI-Generated-Summary using the Human-Generated-Summary using a 10-point scale. Justify your score. Write your score response in score brackets: <score></score> Then write explanation in explanation brackets: <explanation></explanation> </instruction>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee113b79-8ae0-4ba4-8f2d-b91a68f66524",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def should_ignore_path(path):\n",
    "    path_components = path.split(os.sep)\n",
    "    for component in path_components:\n",
    "        if component.startswith('.'):\n",
    "            return True\n",
    "        elif component == 'node_modules':\n",
    "            return True\n",
    "        elif component == '__pycache__':\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da219b6b-31e0-4378-afd3-0a0000917cf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_repo_url(repo_url):\n",
    "  \n",
    "    # Match the pattern github.com/owner/repo\n",
    "    match = re.search(r'github.com/([^/]+)/([^/]+)', repo_url)\n",
    "  \n",
    "    if match:\n",
    "        owner = match.group(1)\n",
    "        repo_name = match.group(2)[:-4]\n",
    "        return owner, repo_name\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid repo URL: {repo_url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "961fd4b72b239aec",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_code_repo_files(repo_url, prompts):\n",
    "    # Temporary clone location\n",
    "    repo_owner, repo_name = parse_repo_url(repo_url)\n",
    "    tmp_dir = f\"tmp/code/{datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')}\"\n",
    "    destination_folder = 'repositories/code'\n",
    "\n",
    "    if not os.path.exists(destination_folder):\n",
    "        os.makedirs(destination_folder)\n",
    "\n",
    "    # Clone the repository\n",
    "    logger.info(f\"Cloning repository... {repo_url}\")\n",
    "    clone_repo(repo_url, token_name, tmp_dir)\n",
    "    logger.info(f\"Finished cloning repository {repo_url}\")\n",
    "\n",
    "    # Copy all files to destination folder\n",
    "    for src_dir, dirs, files in os.walk(tmp_dir):\n",
    "        dst_dir = src_dir.replace(tmp_dir, destination_folder)\n",
    "        if not os.path.exists(dst_dir):\n",
    "            os.mkdir(dst_dir)\n",
    "        for file_ in files:\n",
    "            src_file = os.path.join(src_dir, file_)\n",
    "            dst_file = os.path.join(dst_dir, file_)\n",
    "            if os.path.exists(dst_file):\n",
    "                os.remove(dst_file)\n",
    "            shutil.copy(src_file, dst_dir)\n",
    "\n",
    "    # Delete temp clone\n",
    "    shutil.rmtree(tmp_dir)\n",
    "    processed_files = []\n",
    "    failed_files = []\n",
    "\n",
    "    logger.info(f\"Processing code files in {destination_folder}\")\n",
    "    for root, dirs, files in os.walk(destination_folder):\n",
    "        if not should_ignore_path(root):\n",
    "            for file in files:\n",
    "                if include_code_file_type(file):\n",
    "\n",
    "                    file_path = os.path.join(root, file)\n",
    "\n",
    "                    for attempt in range(3):\n",
    "                        try:\n",
    "                            logger.info(f\"\\033[92mProcessing code file: {file_path}\\033[0m\")\n",
    "                            for prompt in prompts:\n",
    "                                answer = ask_question_to_gen_code_doc(prompt, file_path)\n",
    "                                upload_prompt_answer_and_file_name(file_path, prompt, answer, repo_url) \n",
    "                            # Upload the file itself to the index\n",
    "                            code = open(file_path, 'r')\n",
    "                            upload_prompt_answer_and_file_name(file_path, \"\", code.read(), repo_url)\n",
    "                            processed_files.append(file)\n",
    "                            break\n",
    "                        except Exception as e:\n",
    "                            logger.error(f\"Error: {e}\")\n",
    "                            time.sleep(15)\n",
    "                    else:\n",
    "                        logger.info(f\"\\033[93mSkipping file: {file_path}\\033[0m\")\n",
    "                        failed_files.append(file_path)\n",
    "    return repo_name\n",
    "    logger.info(f\"Processed files: {processed_files}\")\n",
    "    logger.info(f\"Failed files: {failed_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "af835f5d-5e03-4ac8-b7e5-877e086f68f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_doc_repo_files(repo_url, doc_subdir, suffix_exc, gen_doc_summary_prompt, doc_eval_prompt, code_repo):\n",
    "    # Temporary clone location\n",
    "    repo_owner, repo_name = parse_repo_url(repo_url)\n",
    "    tmp_dir = f\"tmp/doc/{datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')}\"\n",
    "    destination_folder = \"repositories/doc\"\n",
    "    eval_folder = \"repositories/eval_results\"\n",
    "\n",
    "    if not os.path.exists(destination_folder):\n",
    "        os.makedirs(destination_folder)\n",
    "\n",
    "    # Clone the repository\n",
    "    logger.info(f\"Cloning repository... {repo_url}\")\n",
    "    clone_repo(repo_url, token_name, tmp_dir)\n",
    "    logger.info(f\"Finished cloning repository {repo_url}\")\n",
    "\n",
    "    # Copy all files from a selected dir\n",
    "    subdir = f\"{tmp_dir}/{doc_subdir}\"\n",
    "    for src_dir, dirs, files in os.walk(subdir):\n",
    "        for file_ in files:\n",
    "            if include_doc_file_type(file_) and src_dir == subdir and suffix_exc in file_:\n",
    "                src_file = os.path.join(src_dir, file_)\n",
    "                dst_file = os.path.join(destination_folder, file_)\n",
    "                if os.path.exists(dst_file):\n",
    "                    os.remove(dst_file)\n",
    "                shutil.copy(src_file, destination_folder)\n",
    "\n",
    "    # Delete temp clone\n",
    "    shutil.rmtree(tmp_dir)\n",
    "\n",
    "    processed_files = []\n",
    "    failed_files = []\n",
    "\n",
    "    gen_doc_summary_prompt = gen_doc_summary_prompt.replace(\"<repo_name>\", code_repo)\n",
    "    \n",
    "    logger.info(f\"Processing doc files in {destination_folder}\")\n",
    "    for file in os.listdir(destination_folder):\n",
    "        file_path = os.path.join(destination_folder, file)\n",
    "        filename = file.split(\".\")[0]\n",
    "        functionality = filename.replace(suffix_exc, \"\").capitalize()\n",
    "        eval_path = f\"{eval_folder}/{filename}\"\n",
    "        if not os.path.exists(eval_path):\n",
    "            os.makedirs(eval_path)\n",
    "        for attempt in range(3):\n",
    "            try:\n",
    "                logger.info(f\"\\033[92mProcessing doc file: {file}\\033[0m\")\n",
    "                gen_doc_summary_prompt_func = gen_doc_summary_prompt.replace(\"<functionality>\", functionality)\n",
    "                ai_doc = ask_question_to_gen_doc_summary(gen_doc_summary_prompt_func)\n",
    "                human_doc = open(file_path, 'r').read()\n",
    "                eval_results = ask_question_to_compare_docs(doc_eval_prompt, human_doc, ai_doc)\n",
    "                save_answers(ai_doc, \"AI-Generated-Doc\", eval_path)\n",
    "                save_answers(human_doc, \"Human-Generated-Doc\", eval_path)\n",
    "                save_answers(eval_results, \"Evaluation\", eval_path)\n",
    "                shutil.move(file_path, eval_path)\n",
    "                processed_files.append(file)\n",
    "                break\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error: {e}\")\n",
    "                time.sleep(15)\n",
    "        else:\n",
    "            logger.info(f\"\\033[93mSkipping file: {file_path}\\033[0m\")\n",
    "            failed_files.append(file_path)\n",
    "\n",
    "    logger.info(f\"Processed files: {processed_files}\")\n",
    "    logger.info(f\"Failed files: {failed_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847b865b-6947-47de-9f13-9df293aa723b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-28 10:54:36 INFO Cloning repository... https://github.com/bayer-int/dse-apis.git\n",
      "2024-03-28 10:54:47 INFO Finished cloning repository https://github.com/bayer-int/dse-apis.git\n",
      "2024-03-28 10:54:48 INFO Processing code files in repositories/code\n",
      "2024-03-28 10:54:48 INFO \u001b[92mProcessing code file: repositories/code/Makefile\u001b[0m\n",
      "2024-03-28 10:55:26 INFO \u001b[92mProcessing code file: repositories/code/go.sum\u001b[0m\n",
      "2024-03-28 10:56:36 INFO \u001b[92mProcessing code file: repositories/code/go.mod\u001b[0m\n",
      "2024-03-28 10:57:10 INFO \u001b[92mProcessing code file: repositories/code/buf.gen.yaml\u001b[0m\n",
      "2024-03-28 10:57:30 INFO \u001b[92mProcessing code file: repositories/code/buf.lock\u001b[0m\n",
      "2024-03-28 10:57:50 INFO \u001b[92mProcessing code file: repositories/code/config/util.go\u001b[0m\n",
      "2024-03-28 10:58:22 INFO \u001b[92mProcessing code file: repositories/code/generated/graphql/generated.go\u001b[0m\n",
      "2024-03-28 10:58:52 INFO \u001b[92mProcessing code file: repositories/code/generated/proto/accounts/v1/accounts_dynamo.pb.go\u001b[0m\n",
      "2024-03-28 10:59:14 INFO \u001b[92mProcessing code file: repositories/code/generated/proto/accounts/v1/accounts.pb.gw.go\u001b[0m\n",
      "2024-03-28 11:00:00 INFO \u001b[92mProcessing code file: repositories/code/generated/proto/accounts/v1/accounts.pb.go\u001b[0m\n",
      "2024-03-28 11:00:54 INFO \u001b[92mProcessing code file: repositories/code/generated/proto/accounts/v1/accounts_grpc.pb.go\u001b[0m\n",
      "2024-03-28 11:01:30 INFO \u001b[92mProcessing code file: repositories/code/generated/proto/events/v1/events.pb.go\u001b[0m\n",
      "2024-03-28 11:02:41 INFO \u001b[92mProcessing code file: repositories/code/generated/proto/events/v1/events.pb.gw.go\u001b[0m\n",
      "2024-03-28 11:03:21 INFO \u001b[92mProcessing code file: repositories/code/generated/proto/events/v1/events_dynamo.pb.go\u001b[0m\n",
      "2024-03-28 11:03:44 INFO \u001b[92mProcessing code file: repositories/code/generated/proto/events/v1/events_grpc.pb.go\u001b[0m\n",
      "2024-03-28 11:04:17 INFO \u001b[92mProcessing code file: repositories/code/generated/proto/tenants/v1/tenants_dynamo.pb.go\u001b[0m\n",
      "2024-03-28 11:04:41 INFO \u001b[92mProcessing code file: repositories/code/generated/proto/tenants/v1/tenants_grpc.pb.go\u001b[0m\n",
      "2024-03-28 11:05:19 INFO \u001b[92mProcessing code file: repositories/code/generated/proto/tenants/v1/tenants.pb.go\u001b[0m\n",
      "2024-03-28 11:06:33 INFO \u001b[92mProcessing code file: repositories/code/generated/proto/tenants/v1/tenants.pb.gw.go\u001b[0m\n",
      "2024-03-28 11:07:17 INFO \u001b[92mProcessing code file: repositories/code/generated/proto/audit/audit.pb.go\u001b[0m\n",
      "2024-03-28 11:07:52 INFO \u001b[92mProcessing code file: repositories/code/generated/proto/audit/audit_dynamo.pb.go\u001b[0m\n",
      "2024-03-28 11:08:14 INFO \u001b[92mProcessing code file: repositories/code/generated/proto/assetstack/v1/assetstacks_grpc.pb.go\u001b[0m\n",
      "2024-03-28 11:08:51 INFO \u001b[92mProcessing code file: repositories/code/generated/proto/assetstack/v1/assetstacks.pb.gw.go\u001b[0m\n",
      "2024-03-28 11:09:39 INFO \u001b[92mProcessing code file: repositories/code/generated/proto/assetstack/v1/assetstacks.pb.go\u001b[0m\n",
      "2024-03-28 11:11:00 INFO \u001b[92mProcessing code file: repositories/code/generated/proto/assetstack/v1/assetstacks_dynamo.pb.go\u001b[0m\n",
      "2024-03-28 11:11:24 INFO \u001b[92mProcessing code file: repositories/code/generated/proto/resources/v1/resources_grpc.pb.go\u001b[0m\n",
      "2024-03-28 11:12:06 INFO \u001b[92mProcessing code file: repositories/code/generated/proto/resources/v1/resources_dynamo.pb.go\u001b[0m\n",
      "2024-03-28 11:12:43 INFO \u001b[92mProcessing code file: repositories/code/generated/proto/resources/v1/resources.pb.go\u001b[0m\n",
      "2024-03-28 11:12:54 INFO \u001b[92mProcessing code file: repositories/code/generated/proto/resources/v1/resources.pb.gw.go\u001b[0m\n",
      "2024-03-28 11:13:48 INFO \u001b[92mProcessing code file: repositories/code/deploy/dse-assetstacks-api/values.yaml\u001b[0m\n",
      "2024-03-28 11:14:14 INFO \u001b[92mProcessing code file: repositories/code/deploy/dse-assetstacks-api/Chart.yaml\u001b[0m\n",
      "2024-03-28 11:14:35 INFO \u001b[92mProcessing code file: repositories/code/deploy/dse-assetstacks-api/templates/hpa.yaml\u001b[0m\n",
      "2024-03-28 11:15:05 INFO \u001b[92mProcessing code file: repositories/code/deploy/dse-assetstacks-api/templates/_helpers.tpl\u001b[0m\n",
      "2024-03-28 11:15:33 INFO \u001b[92mProcessing code file: repositories/code/deploy/dse-assetstacks-api/templates/serviceaccount.yaml\u001b[0m\n",
      "2024-03-28 11:15:57 INFO \u001b[92mProcessing code file: repositories/code/deploy/dse-assetstacks-api/templates/virtualservice.yaml\u001b[0m\n",
      "2024-03-28 11:16:21 INFO \u001b[92mProcessing code file: repositories/code/deploy/dse-assetstacks-api/templates/deployment.yaml\u001b[0m\n",
      "2024-03-28 11:16:48 INFO \u001b[92mProcessing code file: repositories/code/deploy/dse-assetstacks-api/templates/policy.yaml\u001b[0m\n",
      "2024-03-28 11:17:17 INFO \u001b[92mProcessing code file: repositories/code/deploy/dse-assetstacks-api/templates/service.yaml\u001b[0m\n",
      "2024-03-28 11:17:42 INFO \u001b[92mProcessing code file: repositories/code/deploy/dse-assetstacks-api/templates/configmap.yaml\u001b[0m\n",
      "2024-03-28 11:18:05 INFO \u001b[92mProcessing code file: repositories/code/deploy/dse-accounts-api/values.yaml\u001b[0m\n",
      "2024-03-28 11:18:32 INFO \u001b[92mProcessing code file: repositories/code/deploy/dse-accounts-api/Chart.yaml\u001b[0m\n",
      "2024-03-28 11:18:56 INFO \u001b[92mProcessing code file: repositories/code/deploy/dse-accounts-api/templates/hpa.yaml\u001b[0m\n",
      "2024-03-28 11:19:21 INFO \u001b[92mProcessing code file: repositories/code/deploy/dse-accounts-api/templates/_helpers.tpl\u001b[0m\n",
      "2024-03-28 11:19:47 INFO \u001b[92mProcessing code file: repositories/code/deploy/dse-accounts-api/templates/serviceaccount.yaml\u001b[0m\n",
      "2024-03-28 11:20:12 INFO \u001b[92mProcessing code file: repositories/code/deploy/dse-accounts-api/templates/virtualservice.yaml\u001b[0m\n",
      "2024-03-28 11:20:37 INFO \u001b[92mProcessing code file: repositories/code/deploy/dse-accounts-api/templates/deployment.yaml\u001b[0m\n",
      "2024-03-28 11:21:05 INFO \u001b[92mProcessing code file: repositories/code/deploy/dse-accounts-api/templates/policy.yaml\u001b[0m\n",
      "2024-03-28 11:21:29 INFO \u001b[92mProcessing code file: repositories/code/deploy/dse-accounts-api/templates/service.yaml\u001b[0m\n",
      "2024-03-28 11:21:53 INFO \u001b[92mProcessing code file: repositories/code/deploy/dse-accounts-api/templates/configmap.yaml\u001b[0m\n",
      "2024-03-28 11:22:18 INFO \u001b[92mProcessing code file: repositories/code/deploy/dse-events-api/values.yaml\u001b[0m\n",
      "2024-03-28 11:22:48 INFO \u001b[92mProcessing code file: repositories/code/deploy/dse-events-api/Chart.yaml\u001b[0m\n",
      "2024-03-28 11:23:11 INFO \u001b[92mProcessing code file: repositories/code/deploy/dse-events-api/templates/hpa.yaml\u001b[0m\n",
      "2024-03-28 11:23:35 INFO \u001b[92mProcessing code file: repositories/code/deploy/dse-events-api/templates/_helpers.tpl\u001b[0m\n",
      "2024-03-28 11:24:03 INFO \u001b[92mProcessing code file: repositories/code/deploy/dse-events-api/templates/serviceaccount.yaml\u001b[0m\n",
      "2024-03-28 11:24:27 INFO \u001b[92mProcessing code file: repositories/code/deploy/dse-events-api/templates/virtualservice.yaml\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "code_repo_name = process_code_repo_files(code_repo, file_doc_gen_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "495095dd-d4df-46c8-996f-ab1d7d3a1d50",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-28 13:43:33 INFO Cloning repository... https://github.com/bayer-int/DSE-DevDocs.git\n",
      "2024-03-28 13:43:34 INFO Finished cloning repository https://github.com/bayer-int/DSE-DevDocs.git\n",
      "2024-03-28 13:43:34 INFO Processing doc files in repositories/doc\n",
      "2024-03-28 13:43:34 INFO \u001b[92mProcessing doc file: EventsAPI.md\u001b[0m\n",
      "2024-03-28 13:43:46 INFO \u001b[92mProcessing doc file: modelsAPI.md\u001b[0m\n",
      "2024-03-28 13:43:59 INFO \u001b[92mProcessing doc file: ApplicationsAPI.md\u001b[0m\n",
      "2024-03-28 13:44:12 INFO \u001b[92mProcessing doc file: DataScienceProductsAPI.md\u001b[0m\n",
      "2024-03-28 13:44:23 INFO \u001b[92mProcessing doc file: tenantsAPI.md\u001b[0m\n",
      "2024-03-28 13:44:36 INFO \u001b[92mProcessing doc file: DeploymentsAPI.md\u001b[0m\n",
      "2024-03-28 13:44:46 INFO \u001b[92mProcessing doc file: DecisionsAPI.md\u001b[0m\n",
      "2024-03-28 13:44:59 INFO \u001b[92mProcessing doc file: PromotionsAPI.md\u001b[0m\n",
      "2024-03-28 13:45:09 INFO Processed files: ['EventsAPI.md', 'modelsAPI.md', 'ApplicationsAPI.md', 'DataScienceProductsAPI.md', 'tenantsAPI.md', 'DeploymentsAPI.md', 'DecisionsAPI.md', 'PromotionsAPI.md']\n",
      "2024-03-28 13:45:09 INFO Failed files: []\n"
     ]
    }
   ],
   "source": [
    "code_repo_name = \"dse-apis\"\n",
    "process_doc_repo_files(doc_repo, doc_repo_subdir, suffix, file_doc_summary_gen_prompt, file_doc_eval_prompt, code_repo_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170564be-ed27-497a-b5ef-b8e0b8d83de6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
